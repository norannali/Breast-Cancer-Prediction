# Breast Cancer Prediction

## üìú Introduction

This project aims to predict the likelihood of breast cancer based on various features of tumor cells. The dataset used for this project contains information about the characteristics of cell nuclei present in breast cancer biopsies. Using machine learning techniques, we will analyze the data to classify whether a tumor is malignant or benign.

The goal of this project is to build a classification model to predict the diagnosis (Malignant or Benign) based on features like radius, texture, smoothness, compactness, etc.

## üßë‚Äçüíª Dataset Overview

The dataset contains several features describing the characteristics of the cell nuclei, including:

- **ID**: Unique identifier for each patient.
- **Diagnosis**: Diagnosis of breast cancer (M = Malignant, B = Benign).
- **Radius**: The mean of distances from center to points on the perimeter.
- **Texture**: Standard deviation of gray-scale values.
- **Perimeter**: Perimeter of the tumor.
- **Area**: Area of the tumor.
- **Smoothness**: Local variation in radius lengths.
- **Compactness**: Perimeter^2 / Area - 1.0.
- **Concavity**: Severity of concave portions of the contour.
- **Concave Points**: Number of concave portions of the contour.
- **Symmetry**: Symmetry of the tumor.
- **Fractal Dimension**: Coastline approximation - 1.

## üóÇÔ∏è Files in this Repository

- **`Breast_Cancer_Prediction.ipynb`**: Jupyter notebook with the full analysis, including data preprocessing, exploratory data analysis (EDA), and machine learning model building.
- **`breast_cancer.csv`**: The dataset used for the analysis.
- **`requirements.txt`**: List of Python dependencies required for running the analysis.
- **`model.pkl`**: (Optional) Saved model if applicable for future predictions.

## üßë‚Äçüíª Techniques Used

### 1. **Data Preprocessing**:
   - Handling missing values (if any).
   - Encoding categorical variables such as the diagnosis column.
   - Feature scaling to normalize the data (important for distance-based algorithms).

### 2. **Exploratory Data Analysis (EDA)**:
   - Summary statistics and distribution of features.
   - Visualizing correlations between different features.
   - Plotting histograms, boxplots, and pair plots to understand the relationships between features.

### 3. **Machine Learning Models**:
   - **Logistic Regression**: To classify the tumors as malignant or benign.
   - **K-Nearest Neighbors (KNN)**: A non-parametric method used for classification.
   - **Support Vector Machines (SVM)**: To classify the tumors into different categories based on hyperplanes.
   - **Random Forest Classifier**: An ensemble learning method for classification.

### 4. **Model Evaluation**:
   - Evaluating the models using accuracy, precision, recall, F1-score, and the confusion matrix.
   - Cross-validation to check the model's performance on different subsets of data.

## üìä Visualizations Used

- **Feature Distributions**: Visualize the distribution of key features like radius, area, and smoothness for both malignant and benign tumors.
- **Correlation Matrix**: Heatmap showing the correlation between different features.
- **Pair Plots**: Visualizing relationships between features and the target variable (diagnosis).
- **ROC Curve**: Evaluating the performance of classifiers based on the area under the curve (AUC).

## üõ†Ô∏è Libraries and Tools Used

- `pandas`: For data manipulation and analysis.
- `numpy`: For numerical operations.
- `matplotlib` and `seaborn`: For plotting and visual exploration.
- `scikit-learn`: For building and evaluating machine learning models.
- `joblib`: For saving and loading models (if applicable).

## üîç Insights and Findings

- **Malignant vs. Benign**: By analyzing the data, we found that there are distinguishable patterns in features like radius, area, and smoothness that separate malignant and benign tumors.
- **Feature Importance**: Using models like Random Forest, we were able to identify the most important features for classification, such as radius and texture.

## üöÄ Next Steps

- **Improve Model Performance**: Experiment with additional models such as Gradient Boosting and XGBoost.
- **Hyperparameter Tuning**: Tune hyperparameters of the machine learning models to improve accuracy using GridSearchCV or RandomizedSearchCV.
- **Deploy the Model**: Deploy the trained model into a web or mobile application for real-time predictions.


